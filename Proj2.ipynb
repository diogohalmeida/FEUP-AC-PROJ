{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy import stats\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading loans\n",
    "\n",
    "loan = pd.read_csv(\"dataset/loan_train.csv\", sep=\";\")\n",
    "loan_test = pd.read_csv(\"dataset/loan_test.csv\", sep=\";\")\n",
    "\n",
    "loan_no_id = loan.drop(columns=[\"loan_id\"])\n",
    "loan_test_no_id = loan_test.drop(columns=[\"loan_id\"])\n",
    "\n",
    "\n",
    "loan_test_no_id.drop(columns=[\"status\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "all_inputs = loan_no_id.drop(columns=[\"status\"]).values\n",
    "all_labels = loan_no_id[\"status\"].values\n",
    "\n",
    "(inputs_train, inputs_test, labels_train, labels_test) = train_test_split(all_inputs, all_labels, random_state=1, test_size=0.25, stratify=loan_no_id['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1, -1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1, -1,  1,  1,  1,\n",
       "        1,  1,  1,  1, -1, -1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1, -1,\n",
       "        1,  1,  1,  1, -1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1, -1, -1,\n",
       "        1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1, -1,  1, -1,  1, -1, -1,\n",
       "        1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, -1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, -1,  1,  1,  1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling\n",
    "os = SMOTE(random_state=1)\n",
    "os_inputs, os_labels = os.fit_resample(inputs_train, labels_train)\n",
    "print(Counter(labels_train))\n",
    "print(Counter(os_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "dt_grid_search = GridSearchCV(dt_classifier, scoring=\"roc_auc\", cv=10, param_grid={})\n",
    "dt_grid_search.fit(os_inputs, os_labels)\n",
    "print('Best score: {}'.format(dt_grid_search.best_score_))\n",
    "\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = dt_grid_search.predict(inputs_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(labels_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(labels_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(labels_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = dt_grid_search.predict(inputs_test) \n",
    "print(\"F1 Score: {}\".format(f1_score(labels_test, predictions_test)))\n",
    "print(f\"ROC: {roc_auc_score(labels_test, predictions_test)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(labels_test, predictions_test, target_names=['not pay', 'pay']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.6201816502463054\n",
      "=====================================================\n",
      "TRAIN\n",
      "F1 Score: 1.0\n",
      "ROC: 1.0\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not pay       1.00      1.00      1.00        35\n",
      "         pay       1.00      1.00      1.00       211\n",
      "\n",
      "    accuracy                           1.00       246\n",
      "   macro avg       1.00      1.00      1.00       246\n",
      "weighted avg       1.00      1.00      1.00       246\n",
      "\n",
      "=====================================================\n",
      "TEST\n",
      "F1 Score: 1.0\n",
      "ROC: 1.0\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     not pay       1.00      1.00      1.00        11\n",
      "         pay       1.00      1.00      1.00        71\n",
      "\n",
      "    accuracy                           1.00        82\n",
      "   macro avg       1.00      1.00      1.00        82\n",
      "weighted avg       1.00      1.00      1.00        82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = RandomForestClassifier()\n",
    "\n",
    "dt_grid_search = GridSearchCV(dt_classifier, scoring=\"roc_auc\", cv=10, param_grid={})\n",
    "dt_grid_search.fit(all_inputs, all_labels)\n",
    "print('Best score: {}'.format(dt_grid_search.best_score_))\n",
    "\n",
    "\n",
    "print(53 * '=')\n",
    "print(\"TRAIN\")\n",
    "predictions_train = dt_grid_search.predict(inputs_train)\n",
    "print(\"F1 Score: {}\".format(f1_score(labels_train, predictions_train)))\n",
    "print(f\"ROC: {roc_auc_score(labels_train, predictions_train)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(labels_train, predictions_train, target_names=['not pay', 'pay']))\n",
    "print(53 * '=')\n",
    "print(\"TEST\")\n",
    "predictions_test = dt_grid_search.predict(inputs_test) \n",
    "print(\"F1 Score: {}\".format(f1_score(labels_test, predictions_test)))\n",
    "print(f\"ROC: {roc_auc_score(labels_test, predictions_test)}\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(labels_test, predictions_test, target_names=['not pay', 'pay']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mechjm/.local/lib/python3.8/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7279</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7286</th>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7292</th>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294</th>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295</th>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted\n",
       "Id             \n",
       "4962       0.52\n",
       "4967       0.40\n",
       "4968       0.34\n",
       "4986       0.12\n",
       "4988       0.47\n",
       "...         ...\n",
       "7279       0.12\n",
       "7286       0.06\n",
       "7292       0.17\n",
       "7294       0.10\n",
       "7295       0.20\n",
       "\n",
       "[354 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = dt_grid_search.predict_proba(loan_test_no_id)\n",
    "\n",
    "\n",
    "probabilities = [entry[0] for entry in results]\n",
    "#print(len(probabilities))\n",
    "#print(len(no_ids_test))\n",
    "\n",
    "#print(len(probabilities))\n",
    "loan_ids_index = loan_test[\"loan_id\"]\n",
    "loan_ids_index\n",
    "data = {\"Id\": loan_ids_index, \"Predicted\": probabilities}\n",
    "submission_df = pd.DataFrame(data)\n",
    "submission_df = submission_df.groupby([\"Id\"]).mean()\n",
    "submission_df.to_csv(\"submissions/df.csv\")\n",
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
